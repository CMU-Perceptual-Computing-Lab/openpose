<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>OpenPose: OpenPose Doc - Demo</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="Logo_doxygen_black.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OpenPose
   &#160;<span id="projectnumber">1.7.0</span>
   </div>
   <div id="projectbrief">The first real-time multi-person system to jointly detect human body, hand, facial, and foot keypoints</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_doc_01_demo.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">OpenPose Doc - Demo </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Forget about the OpenPose code, just download the portable Windows binaries (or compile the code from source) and use the demo by following this tutorial!</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Contents</h1>
<ol type="1">
<li><a href="#quick-start">Quick Start</a><ol type="a">
<li><a href="#running-on-images-video-or-webcam">Running on Images, Video, or Webcam</a></li>
<li><a href="#face-and-hands">Face and Hands</a></li>
<li><a href="#different-outputs-json-images-video-ui">Different Outputs (JSON, Images, Video, UI)</a></li>
<li><a href="#only-skeleton-without-background-image">Only Skeleton without Background Image</a></li>
<li><a href="#not-running-all-gpus">Not Running All GPUs</a></li>
<li><a href="#maximum-accuracy-configuration">Maximum Accuracy Configuration</a><ol type="i">
<li><a href="#additional-model-with-maximum-accuracy">Additional Model with Maximum Accuracy</a></li>
<li><a href="#additional-model-with-lower-false-positives">Additional Model with Lower False Positives</a></li>
</ol>
</li>
<li><a href="#3-d-reconstruction">3-D Reconstruction</a></li>
<li><a href="#tracking">Tracking</a></li>
<li><a href="#kinect-20-as-webcam-on-windows-10">Kinect 2.0 as Webcam on Windows 10</a></li>
<li><a href="#main-flags">Main Flags</a></li>
</ol>
</li>
<li><a href="#advanced-quick-start">Advanced Quick Start</a></li>
<li><a href="#bug-solving">Bug Solving</a><ol type="a">
<li><a href="#improving-memory-and-speed-but-decreasing-accuracy">Improving Memory and Speed but Decreasing Accuracy</a></li>
<li><a href="#mac-osx-additional-step">Mac OSX Additional Step</a></li>
<li><a href="#faq">FAQ</a></li>
</ol>
</li>
</ol>
<h1><a class="anchor" id="autotoc_md15"></a>
Quick Start</h1>
<p>In Ubuntu, Mac, and other Unix systems, use <code>Terminal</code> or <code>Terminator</code>. In Windows, the <code>Windows PowerShell</code>. Watch any Youtube video tutorial if you are not familiar with these tools. Make sure that you are in the <b>root directory of the project</b> when running any command (i.e., in the OpenPose folder, not inside <code>build/</code> nor <code>windows/</code> nor <code>bin/</code>). In addition, <code>examples/media/video.avi</code> and <code>examples/media</code> exist, so there is no need to change any lines of code.</p>
<p>Test OpenPose by running the following. The expected visual result should look like <a href="02_output.md#ui-and-visual-output">doc/02_output.md#ui-and-visual-output</a>. </p><div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi</div>
</div><!-- fragment --><p>If you are only using the OpenPose demo, we highly recommend using <a href="doc/installation/0_index.md#windows-portable-demo">the latest Windows portable version of OpenPose</a>. If you still want to use the demo with Visual Studio, you can copy the <code>bin/*.dll</code> files into the final DLL bin location following <a href="installation/0_index.md#windows">doc/installation/0_index.md#windows</a>, or you could also simply modify the default flag values from <a href="../include/flags.hpp">include/flags.hpp</a>. If you have copied the DLLs, you can execute this: </p><div class="fragment"><div class="line">:: Windows - Library - Assuming you have copied the DLLs following doc/installation/0_index.md#windows</div>
<div class="line">build\x64\Release\OpenPoseDemo.exe --video examples/media/video.avi</div>
</div><!-- fragment --><p>If it worked, continue with the next section. Otherwise:</p><ul>
<li>If these failed with an out of memory error, check and follow the section <a href="#improving-memory-and-speed-but-decreasing-accuracy">Improving Memory and Speed but Decreasing Accuracy</a>.</li>
<li>If you are using Mac, make sure to check and follow the section <a href="#mac-osx-additional-step">Mac OSX Additional Step</a>.</li>
<li>Otherwise, check the section <a href="#faq">FAQ</a>.</li>
</ul>
<h2><a class="anchor" id="autotoc_md16"></a>
Running on Images, Video, or Webcam</h2>
<ul>
<li>Directory with images (<code>--image_dir {DIRECTORY_PATH}</code>): <div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --image_dir examples/media/</div>
</div><!-- fragment --></li>
<li>Video (<code>--video {VIDEO_PATH}</code>): <div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi</div>
</div><!-- fragment --></li>
<li>Webcam is applied by default (i.e., if no <code>--image_dir</code> or <code>--video</code> flags used). Optionally, if you have more than 1 camera, you could use <code>--camera {CAMERA_NUMBER}</code> to select the right one: <div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin</div>
<div class="line">./build/examples/openpose/openpose.bin --camera 0</div>
<div class="line">./build/examples/openpose/openpose.bin --camera 1</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe</div>
<div class="line">bin\OpenPoseDemo.exe --camera 0</div>
<div class="line">bin\OpenPoseDemo.exe --camera 1</div>
</div><!-- fragment --></li>
</ul>
<h2><a class="anchor" id="autotoc_md17"></a>
Face and Hands</h2>
<p>Simply add <code>--face</code> and/or <code>--hand</code> to any command: </p><div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/ --face --hand</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --face --hand</div>
<div class="line">./build/examples/openpose/openpose.bin --face --hand</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --image_dir examples/media/ --face --hand</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --face --hand</div>
<div class="line">bin\OpenPoseDemo.exe --face --hand</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md18"></a>
Different Outputs (JSON, Images, Video, UI)</h1>
<p>All the output options are complementary to each other. E.g., whether you display the images with the skeletons on the UI (or not) is independent on whether you save them on disk (or not).</p>
<ul>
<li>Save the skeletons in a set of JSON files with <code>--write_json {OUTPUT_JSON_PATH}</code>, see <a class="el" href="md_doc_02_output.html">doc/02_output.md</a> to understand its format. <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/ --write_json output_jsons/</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json output_jsons/</div>
<div class="line">./build/examples/openpose/openpose.bin --write_json output_jsons/</div>
</div><!-- fragment --></li>
<li>Save on disk the visual output of OpenPose (the images with the skeletons overlaid) as an output video (<code>--write_video {OUTPUT_VIDEO_PATH}</code>) or set of images (<code>--write_images {OUTPUT_IMAGE_DIRECTORY_PATH}</code>.: <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_video output/result.avi</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/ --write_video output/result.avi</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_images output_images/</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_images output_images/ --write_images_format jpg</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/ --write_images output_images/</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir examples/media/ --write_images output_images/ --write_images_format jpg</div>
</div><!-- fragment --></li>
<li>You can also disable the UI visualization with <code>--display 0</code>. However, some kind of output must be generated. I.e., set one out of <code>--write_json</code>, <code>--write_video</code>, or <code>--write_images</code> if <code>--display 0</code>. <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_images output_images/ --display 0</div>
</div><!-- fragment --></li>
<li>To speed up OpenPose even further when using <code>--display 0</code>, also add <code>--render_pose 0</code> if you are not using <code>--write_video</code> or <code>--write_images</code> (so OpenPose will not overlay skeletons with the input images). <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --write_json output_jsons/ --display 0 --render_pose 0</div>
</div><!-- fragment --></li>
</ul>
<h1><a class="anchor" id="autotoc_md19"></a>
Only Skeleton without Background Image</h1>
<p>You can also visualize/save the skeleton without the original image overlaid or blended by adding <code>--disable_blending</code>: </p><div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line"># Only body</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --disable_blending</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md20"></a>
Not Running All GPUs</h1>
<p>By default, OpenPose will use all the GPUs available in your machine. Otherwise, <code>--num_gpu</code> sets the number of total GPUs and <code>--num_gpu_start</code> the first GPU to use. E.g., <code>--num_gpu 2 --num_gpu_start 1</code> will use GPUs ID 1 and 2 while ignore GPU ID 0 (assuming there are at least 3 GPUs): </p><div class="fragment"><div class="line">:: Windows - Portable Demo (same flags for Ubuntu and Mac)</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --num_gpu 2 --num_gpu_start 1</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md21"></a>
Maximum Accuracy Configuration</h2>
<p>This command provides the most accurate results we have been able to achieve for body, hand and face keypoint detection. </p><div class="fragment"><div class="line"># Ubuntu and Mac: Body</div>
<div class="line">./build/examples/openpose/openpose.bin --net_resolution &quot;1312x736&quot; --scale_number 4 --scale_gap 0.25</div>
<div class="line"># Ubuntu and Mac: Body + Hand + Face</div>
<div class="line">./build/examples/openpose/openpose.bin --net_resolution &quot;1312x736&quot; --scale_number 4 --scale_gap 0.25 --hand --hand_scale_number 6 --hand_scale_range 0.4 --face</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo: Body</div>
<div class="line">bin\OpenPoseDemo.exe --net_resolution &quot;1312x736&quot; --scale_number 4 --scale_gap 0.25</div>
<div class="line">:: Windows - Portable Demo: Body + Hand + Face</div>
<div class="line">bin\OpenPoseDemo.exe --net_resolution &quot;1312x736&quot; --scale_number 4 --scale_gap 0.25 --hand --hand_scale_number 6 --hand_scale_range 0.4 --face</div>
</div><!-- fragment --><ul>
<li>Required:<ul>
<li><code>BODY_25</code> (default model). <code>COCO</code> is less accurate (but still usable), while <code>MPI</code> is not supported (i.e., <code>MPI</code> accuracy and speed will drop by using these settings).</li>
<li>Nvidia GPU with at least 16 GB of memory. 8 or 12 GB could work in some subcases detailed here.<ul>
<li><code>BODY_25</code> (body + foot, default model): Nvidia GPU with at least about 10.5 GB of memory. E.g., Titan X(P), some Quadro models, P100, V100.</li>
<li><code>BODY_25</code> + face + hands: Nvidia GPU with at least about 16 GB of memory. E.g., V100.</li>
<li><code>COCO</code> Body + face + hands: Nvidia GPU with at least about 6.7 GB of memory. E.g., 2070, 2080.</li>
</ul>
</li>
<li>It won't work on CPU/OpenCL modes, your only option there is to manually crop each person, rescale it, and fed it into the default OpenPose</li>
</ul>
</li>
<li>Additional information:<ul>
<li>It runs at about 2 FPS on a Titan X for <code>BODY_25</code> (1 FPS for COCO).</li>
<li>Increasing <code>--net_resolution</code> will highly reduce speed, while it does not guarantee the accuracy to increase. Thus, we recommend only using the exact flags and values detailed here (or alternatively ask the user to make their own accuracy analysis if using other values).</li>
<li>(Not recommended, use at your own risk) You can add <code>--maximize_positives</code> to harm the visual/qualitative accuracy, but it increases the accuracy value metric on COCO challenge. It reduces the thresholds to accept a person candidate (i.e., more false and true positives), which maximizes average recall but could harm average precision. Our experience: it looks much worse visually, but improves the challenge accuracy numbers.</li>
<li>If you are operating on Ubuntu, you can check the experimental scripts that we use to test our accuracy (we do not officially support it, i.e., we will not answer questions about it, as well as it might change it continuously), they are placed in <code>openpose/scripts/tests/</code>, called <code>pose_accuracy_coco_test_dev.sh</code> and <code>pose_accuracy_coco_val.sh</code>.</li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md22"></a>
Additional Model with Maximum Accuracy</h3>
<p>Disclaimer: It is more accurate but also slower, requires more GPU memory, and must use the Nvidia GPU version.</p>
<p>Our paper accuracy numbers do not match the default model numbers. We released our best model at the time but found better ones later.</p>
<p>For our best model, you can download the <code>BODY_25B</code> pre-trained model from the OpenPose training repository: <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose_train/tree/master/experimental_models#body_25b-model---option-1-maximum-accuracy-less-speed">BODY_25B Model - Option 1 (Maximum Accuracy, Less Speed)</a>.</p>
<h3><a class="anchor" id="autotoc_md23"></a>
Additional Model with Lower False Positives</h3>
<p>Disclaimer: It must use the Nvidia GPU version.</p>
<p>Do you need a model with less false positives but the same runtime performance and GPU requirements? You can download the <code>BODY_25B</code> pre-trained model from the OpenPose training repository: <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose_train/tree/master/experimental_models#body_25b-model---option-2-recommended">BODY_25B Model - Option 2 (Recommended)</a>.</p>
<h2><a class="anchor" id="autotoc_md24"></a>
3-D Reconstruction</h2>
<ol type="1">
<li>Real-time demo <div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --3d --number_people_max 1</div>
<div class="line"># With face and hands</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --3d --number_people_max 1 --face --hand</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --flir_camera --3d --number_people_max 1</div>
<div class="line">:: With face and hands</div>
<div class="line">bin\OpenPoseDemo.exe --flir_camera --3d --number_people_max 1 --face --hand</div>
</div><!-- fragment --></li>
<li>Saving 3-D keypoints and video <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --3d --number_people_max 1 --write_json output_folder_path/ --write_video_3d output_folder_path/video_3d.avi</div>
</div><!-- fragment --></li>
<li>Fast stereo camera image saving (without keypoint detection) for later post-processing <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line"># Saving video</div>
<div class="line"># Note: saving in PNG rather than JPG will improve image quality, but slow down FPS (depending on hard disk writing speed and camera number)</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --num_gpu 0 --write_video output_folder_path/video.avi --write_video_fps 5</div>
<div class="line"># Saving images</div>
<div class="line"># Note: saving in PNG rather than JPG will improve image quality, but slow down FPS (depending on hard disk writing speed and camera number)</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --num_gpu 0 --write_images output_folder_path/ --write_images_format jpg</div>
</div><!-- fragment --></li>
<li>Reading and processing previously saved stereo camera images <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line"># Optionally add `--face` and/or `--hand` to include face and/or hands</div>
<div class="line"># Assuming 3 cameras</div>
<div class="line"># Note: We highly recommend to reduce `--output_resolution`. E.g., for 3 cameras recording at 1920x1080, the resulting image is (3x1920)x1080, so we recommend e.g. 640x360 (x3 reduction).</div>
<div class="line"># Video</div>
<div class="line">./build/examples/openpose/openpose.bin --video output_folder_path/video.avi --3d_views 3 --3d --number_people_max 1 --output_resolution {desired_output_resolution}</div>
<div class="line"># Images</div>
<div class="line">./build/examples/openpose/openpose.bin --image_dir output_folder_path/ --3d_views 3 --3d --number_people_max 1 --output_resolution {desired_output_resolution}</div>
</div><!-- fragment --></li>
<li>Reconstruction when the keypoint is visible in at least <code>x</code> camera views out of the total <code>n</code> cameras <div class="fragment"><div class="line"># Ubuntu and Mac (same flags for Windows)</div>
<div class="line"># Reconstruction when a keypoint is visible in at least 2 camera views (assuming `n` &gt;= 2)</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --3d --number_people_max 1 --3d_min_views 2 --output_resolution {desired_output_resolution}</div>
<div class="line"># Reconstruction when a keypoint is visible in at least max(2, min(4, n-1)) camera views</div>
<div class="line">./build/examples/openpose/openpose.bin --flir_camera --3d --number_people_max 1 --output_resolution {desired_output_resolution}</div>
</div><!-- fragment --></li>
</ol>
<h2><a class="anchor" id="autotoc_md25"></a>
Tracking</h2>
<ol type="1">
<li>Runtime huge speed up by reducing the accuracy: <div class="fragment"><div class="line">:: Windows - Portable Demo (same flags for Ubuntu and Mac)</div>
<div class="line"># Using OpenPose 1 frame, tracking the following e.g., 5 frames</div>
<div class="line">bin\OpenPoseDemo.exe --tracking 5 --number_people_max 1</div>
</div><!-- fragment --></li>
<li>Runtime speed up while keeping most of the accuracy: <div class="fragment"><div class="line">:: Windows - Portable Demo (same flags for Ubuntu and Mac)</div>
<div class="line"># Using OpenPose 1 frame and tracking another frame</div>
<div class="line">bin\OpenPoseDemo.exe --tracking 1 --number_people_max 1</div>
</div><!-- fragment --></li>
<li>Visual smoothness: <div class="fragment"><div class="line">:: Windows - Portable Demo (same flags for Ubuntu and Mac)</div>
<div class="line"># Running both OpenPose and tracking on each frame. Note: There is no speed up/slow down</div>
<div class="line">bin\OpenPoseDemo.exe --tracking 0 --number_people_max 1</div>
</div><!-- fragment --></li>
</ol>
<h1><a class="anchor" id="autotoc_md26"></a>
Kinect 2.0 as Webcam on Windows 10</h1>
<p>Since the Windows 10 Anniversary, Kinect 2.0 can be read as a normal webcam. All you need to do is go to <code>device manager</code>, expand the <code>kinect sensor devices</code> tab, right click and update driver of <code>WDF kinectSensor Interface</code>. If you already have another webcam, disconnect it or use <code>--camera 2</code>.</p>
<h2><a class="anchor" id="autotoc_md27"></a>
Main Flags</h2>
<p>These are the most common flags, but check <a class="el" href="md_doc_advanced_demo_advanced.html">doc/advanced/demo_advanced.md</a> for a full list and description of all of them.</p>
<ul>
<li><code>--face</code>: Enables face keypoint detection.</li>
<li><code>--hand</code>: Enables hand keypoint detection.</li>
<li><code>--video input.mp4</code>: Read video <code>input.mp4</code>.</li>
<li><code>--camera 3</code>: Read webcam number 3.</li>
<li><code>--image_dir path_with_images/</code>: Run on the directory <code>path_with_images/</code> with images.</li>
<li><code>--ip_camera <a href="http://iris.not.iac.es/axis-cgi/mjpg/video.cgi?resolution=320x240?x.mjpeg">http://iris.not.iac.es/axis-cgi/mjpg/video.cgi?resolution=320x240?x.mjpeg</a></code>: Run on a streamed IP camera. See examples public IP cameras <a href="http://www.webcamxp.com/publicipcams.aspx">here</a>.</li>
<li><code>--write_video path.avi</code>: Save processed images as video.</li>
<li><code>--write_images folder_path</code>: Save processed images on a folder.</li>
<li><code>--write_keypoint path/</code>: Output JSON, XML or YML files with the people pose data on a folder.</li>
<li><code>--process_real_time</code>: For video, it might skip frames to display at real time.</li>
<li><code>--disable_blending</code>: If enabled, it will render the results (keypoint skeletons or heatmaps) on a black background, not showing the original image. Related: <code>part_to_show</code>, <code>alpha_pose</code>, and <code>alpha_pose</code>.</li>
<li><code>--part_to_show</code>: Prediction channel to visualize.</li>
<li><code>--display 0</code>: Display window not opened. Useful for servers and/or to slightly speed up OpenPose.</li>
<li><code>--num_gpu 2 --num_gpu_start 1</code>: Parallelize over this number of GPUs starting by the desired device id. By default it uses all the available GPUs.</li>
<li><code>--model_pose MPI</code>: Model to use, affects number keypoints, speed and accuracy.</li>
<li><code>--logging_level 3</code>: Logging messages threshold, range [0,255]: 0 will output any message &amp; 255 will output none. Current messages in the range [1-4], 1 for low priority messages and 4 for important ones.</li>
</ul>
<h1><a class="anchor" id="autotoc_md28"></a>
Advanced Quick Start</h1>
<p>In order to learn about many more flags, check <a class="el" href="md_doc_advanced_demo_advanced.html">doc/advanced/demo_advanced.md</a>.</p>
<h1><a class="anchor" id="autotoc_md29"></a>
Bug Solving</h1>
<h2><a class="anchor" id="autotoc_md30"></a>
Improving Memory and Speed but Decreasing Accuracy</h2>
<p><b>If you have a Nvidia GPU that does not goes out of memory when running, you should skip this step!</b></p>
<p><b>Use <code>net_resolution</code> at your own risk</b>: If your GPU runs out of memory or you do not have a Nvidia GPU, you can reduce <code>--net_resolution</code> to improve the speed and reduce the memory requirements, but it will also highly reduce accuracy! The lower the resolution, the lower accuracy but better speed/memory. </p><div class="fragment"><div class="line"># Ubuntu and Mac</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --net_resolution -1x320</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --net_resolution -1x256</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --net_resolution -1x196</div>
<div class="line">./build/examples/openpose/openpose.bin --video examples/media/video.avi --net_resolution -1x128</div>
</div><!-- fragment --> <div class="fragment"><div class="line">:: Windows - Portable Demo</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --net_resolution -1x320</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --net_resolution -1x256</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --net_resolution -1x196</div>
<div class="line">bin\OpenPoseDemo.exe --video examples/media/video.avi --net_resolution -1x128</div>
</div><!-- fragment --><p>Additional notes:</p><ul>
<li>The default resolution is <code>-1x368</code>, any resolution smaller will improve speed.</li>
<li>The <code>-1</code> means that that the resolution will be adapted to maintain the aspect ratio of the input source. E.g., <code>-1x368</code>, <code>656x-1</code>, and <code>656x368</code> will result in the same exact resolution for 720p and 1080p input images.</li>
<li>For videos, using <code>-1</code> is recommended to let OpenPose find the ideal resolution. For a folder of images of different sizes, not adding <code>-1</code> and using images with completely different aspect ratios might result in out of memory issues. E.g., if a folder contains 2 images of resolution <code>100x11040</code> and <code>10000x368</code>. Then, using the default <code>-1x368</code> will result in the network output resolutions of <code>3x368</code> and <code>10000x368</code>, resulting in an obvious out of memory for the <code>10000x368</code> image.</li>
</ul>
<h2><a class="anchor" id="autotoc_md31"></a>
Mac OSX Additional Step</h2>
<p><b>If you are not using Mac, or you are using Mac with <code>CPU_only</code>, you can skip this section.</b></p>
<p>If you are using a Mac and selected <code>OPENCL</code> support, and it has an AMD graphics card, that means that the machine has 2 GPUs that are not compatible with each other (AMD and Intel). Then, you will have to manually select one of them (the AMD one should be more powerful). To do that, first check which device your Graphics card is set under. Most likely, your AMD device will be device 2. </p><div class="fragment"><div class="line">clinfo</div>
</div><!-- fragment --><p>For any OpenPose command you run, add the following 2 flags to use your AMD card for acceleration (where <code>num_gpu_start</code> should be the ID number given above). </p><div class="fragment"><div class="line">./build/examples/openpose/openpose.bin --num_gpu 1 --num_gpu_start 2</div>
</div><!-- fragment --><p>If you only have an integrated Intel Graphics card, then it will most probably be the device 1. Then, always add the following 2 flags to use your AMD card for acceleration. </p><div class="fragment"><div class="line">./build/examples/openpose/openpose.bin --num_gpu 1 --num_gpu_start 1</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md32"></a>
FAQ</h2>
<p>Check <a class="el" href="md_doc_05_faq.html">doc/05_faq.md</a> to see if you can find your error, issue, or concern. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
